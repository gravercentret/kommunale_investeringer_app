import streamlit as st
import polars as pl
import os
import sys
from utils.data_processing import (
    get_data,
    get_unique_kommuner,
    get_unique_categories,
    filter_dataframe_by_choice,
    filter_dataframe_by_category,
    generate_organization_links,
    filter_df_by_search,
    fix_column_types_and_sort,
    format_number_european,
    round_to_million_or_billion,
    get_ai_text,
    to_excel_function,
    load_css,
    write_markdown_sidebar,
    format_and_display_data,
    display_dataframe,
    create_user_session_log,
    cache_data_for_hele_landet,
    cache_excel_for_hele_landet,
)
from utils.plots import create_pie_chart
from config import set_pandas_options, set_streamlit_options

# Apply the settings
set_pandas_options()
set_streamlit_options()
load_css("webapp/style.css")

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

create_user_session_log("Forside")

df_pl = get_data()

st.logo("webapp/images/GC_png_oneline_lockup_Outline_Blaa_RGB.png", link="https://gravercentret.dk/")

st.error("Siden er blevet flyttet - den skal fremover tilg√•s her: https://kommuneinvesteringer.gravercentret.dk/")

# Title of the app
st.title("Kommunernes og regionernes investeringer")

st.markdown(
    """ 
    **Hvis der anvendes data fra dette site i et journalistisk produkt eller i en anden sammenh√¶ng, skal Gravercentret og Danwatch n√¶vnes som kilde.** 
    **F.eks.: ‚ÄùDet viser data, som er indsamlet og bearbejdet af Gravercentret, Danmarks Center for Unders√∏gende Journalistik, i samarbejde med Danwatch."**
            """
)
st.markdown(
    """
            Gravercentret, Danmarks Center for Unders√∏gende Journalistik, har sammen med Danwatch unders√∏gt, hvilke v√¶rdipapirer de danske kommuner og regioner har valgt at investere i. \n
            Vi har kortlagt, hvilke v√¶rdipapirer der ligger nede i de investeringsfonde og investeringsforeninger, som kommunerne og regionerne har sat deres penge i.
            Disse oplysninger har vi sammenholdt med lister over hvilke v√¶rdipapirer, der er sortlistet af danske banker og pensionsselskaber samt FN. \n
            Herunder kan du se oplysninger fra alle kommuner og regioner ‚Äì og du kan downloade oplysningerne i Excel-format.
            I den lysebl√• kolonne til venstre kan du s√∏ge i data.\n
            *OBS: Den 13/12/24 har vi fjernet selskabet Daiichi Sankyo Co. Ltd. fra problemkategorien "Gambling", da selskabet var blevet fejlmatchet med selskabet Sankyo Co. Ltd. Den 24/10, er data opdateret, da vi har fundet flere statsobligationer, der ikke var markeret fra start, og d. 07/11 er data opdateret, da markedsv√¶rdierne for nogle af Odense Kommunes v√¶rdipapirer er tilrettet.*

            """
)

with st.expander("üü•üüßüü® - L√¶s mere: Hvordan skal tallene forst√•s?"):
    st.markdown(
        """
                I tabellen nedenfor finder du informationer om samtlige v√¶rdipapirer danske kommuner og regioner har oplyst at de havde investeret i i sommeren 2024. \n
                For hvert v√¶rdipapir er det angivet, hvilken kommune eller region, der er ejeren, hvad v√¶rdipapirets navn er, og hvor meget v√¶rdipapiret er v√¶rd.\n
                V√¶rdipapirer, der er udpeget som problematiske, har vi markeret med enten en r√∏d, en orange eller en gul firkant.\n
                Alts√• viser farverne om v√¶rdipapiret optr√¶der p√• en eksklusionsliste over papirer danske banker, pensionsselskaber eller FN **ikke** vil investere i af forskellige etiske √•rsager.\n
                Vi har opdelt de problematiske v√¶rdipapirer i tre kategorier:\n
                - üü•(1) - **R√∏d**: Disse v√¶rdipapirer er udstedt af problematiske selskaber.
                - üüß(2) - **Orange**: Disse v√¶rdipapirer er udstedet af problematiske lande.
                - üü®(3) - **Gul**: Disse v√¶rdipapirer er potentielt kontroversielle.\n
                For hvert v√¶rdipapir, der er markeret som problematisk, er der i tabellens kollonne "Eksklusion (Af hvem og hvorfor)" en forklaring p√•, hvem der har udpeget det som problematisk, og hvad √•rsagen er.\n
                Ved at scrolle til h√∏jre i skemaet kan man se en anden kolonne, der hedder ‚Äùsortlistet‚Äù. Her kan man se, hvor mange sorte lister fra danske banker, pensionsselskaber og FN det p√•g√¶ldende v√¶rdipapir er p√•. St√•r der eksempelvis 5, s√• er v√¶rdipapiret alts√• sortlistet af fem forskellige parter.\n
                Som tommelfingerregel kan man sige, at jo flere sorte lister et bestemt v√¶rdipapir er p√•, jo mere problematisk er det.\n
                I tabellen kan du ogs√• se, hvilken type v√¶rdipapiret er (f.eks. aktie eller obligation), v√¶rdipapirets ISIN-nummer (et unikt nummer ligesom et CPR-nummer), samt hvem der har udstedt papiret.\n
                Data kan downloades til Excel neden under tabellen.
                """
    )
    st.markdown(
        'L√¶s mere om vores metode i <a href="/S√•dan_har_vi_gjort" target="_self">her</a>.',
        unsafe_allow_html=True,
    )


with st.expander("S√•dan kommer du i gang.", icon="‚ùî"):
    st.markdown(
        """
    Hvis du vil se oplysninger om en bestemt kommune eller regions investeringer, s√• kan du v√¶lge et omr√•de i menuen ude til venstre her p√• forsiden.\n
    Data bliver s√• automatisk sorteret, s√• du kun ser oplysninger fra den √∏nskede kommune her p√• siden.\n
    L√¶s hvordan du kan forst√• data i afsnittet "Hvordan skal tallene forst√•s?" ovenfor. \n
    Fokuserer du p√• bestemte v√¶rdipapirer, er det god ide at f√• bekr√¶ftet af kommunen eller regionen, at de fortsat ejer v√¶rdipapiret (gennem deres investeringsforening eller fond). Gravercentrets site giver nemlig kun et √∏jebliksbillede af, hvilke v√¶rdipapirer kommunerne oplyste at de ejede i sommeren 2024. \n
    Selv hvis kommunen ikke l√¶ngere skulle eje et bestemt problematisk v√¶rdipapir, s√• kan der fortsat v√¶re en historie i, at de faktisk har ejet det. \n 
    Vil du vide mere om, hvorfor et v√¶rdipapir er problematisk, kan du i tabellen nedenfor se, hvilken bank eller pensionsselskab, der har beskrevet det som problematisk samt hvorfor. \n
    Herefter kan du kontakte de konkrete banker eller pensionsselskaber og bede dem uddybe, hvorfor de har sortlistet v√¶rdipapiret.\n

    """
    )

# Get unique municipalities and sort alphabetically
dropdown_options = get_unique_kommuner(df_pl)

# Get list of categories/reasons
unique_categories_list = get_unique_categories(df_pl)

# Costum choice for dropdown
all_values = "Hele landet"
municipalities = "Alle kommuner"
regions = "Alle regioner"
sams√∏ = "Sams√∏"
l√¶s√∏ = "L√¶s√∏"

# Sidebar with selection options
with st.sidebar:
    user_choice = st.selectbox(
        "V√¶lg omr√•de:",
        dropdown_options,
        help="Skriv i boksen for at s√∏ge efter bestemt kommune/region.",
        placeholder="V√¶lg en kommune/region.",
    )

    selected_categories = st.multiselect(
        "V√¶lg problemkategori:",
        unique_categories_list,  # Options
        help="Vi har grupperet de mange √•rsager til eksklusion i hovedkategorier. V√¶lg √©n eller flere.",
        placeholder="",
    )

    search_query = st.text_input(
        "Fritekst s√∏gning i tabellen:",
        "",
        help="S√∏g f.eks. efter et selskabs navn eller et ISIN-nummer.",
    )

    st.markdown(
        'Klik her for mere <a href="/Avanceret_s√∏gning" target="_self">avanceret s√∏gning</a>.',
        unsafe_allow_html=True,
    )

    # Filter dataframe based on user's selection
    filtered_df = filter_dataframe_by_choice(df_pl, user_choice)

    filtered_df = filter_df_by_search(filtered_df, search_query)

    filtered_df = filter_dataframe_by_category(filtered_df, selected_categories)

    filtered_df = fix_column_types_and_sort(filtered_df)

    if user_choice in [all_values, municipalities, regions] and search_query or selected_categories:
        if search_query:
            st.markdown(
                f"Antal kommuner/regioner, hvor '{search_query}' indg√•r: \n **{filtered_df.select(pl.col('Omr√•de').n_unique()).to_numpy()[0][0]}**"
            )
        else:
            st.markdown(
                f"Antal kommuner/regioner, der fremg√•r efter filtrering: \n **{filtered_df.select(pl.col('Omr√•de').n_unique()).to_numpy()[0][0]}**"
            )

    write_markdown_sidebar()

# Conditionally display the header based on whether a search query is provided
if selected_categories:
    select_string = ", ".join(selected_categories)
if search_query and not selected_categories:
    st.markdown(f"Data for '{user_choice}' og '{search_query}':")
if selected_categories and not search_query:
    st.subheader(f"Data for '{user_choice}' og '{select_string}':")
if selected_categories and search_query:
    st.subheader(f"Data for '{user_choice}', '{select_string}' og '{search_query}':")
if not selected_categories and not search_query:
    if user_choice == "Hele landet":
        st.markdown(
            f"### Data for alle kommuner og regioner: \n ##### (V√¶lg en enkelt kommune eller region i panelet til venstre)"
        )
    else:
        st.subheader(f"Data for '{user_choice}':")

# Create three columns
col1, col2 = st.columns([0.4, 0.6])

# Column 1: Pie chart for "Type" based on "Markedsv√¶rdi (DKK)"
with col1:
    if filtered_df.shape[0] == 0:
        st.subheader(f"**Der er ingen v√¶rdipapirer/investeringer.**")
    else:
        create_pie_chart(filtered_df)

# Column 2: Number of problematic investments
with col2:
    with st.container(border=True):
        header_numbers = "Antal investeringer udpeget som problematiske:"
        st.markdown(
            f"<h4 style='text-align:center;'>{header_numbers}</h4>",
            unsafe_allow_html=True,
        )

        # Count the rows where 'Problematisk if√∏lge:' is not empty
        problematic_count = filtered_df.filter(filtered_df["Priority"].is_in([2, 3])).shape[0]
        problematic_count = format_number_european(problematic_count)
        st.markdown(
            f"<h2 style='text-align:center;'>{problematic_count}</h2>",
            unsafe_allow_html=True,
        )

        problematic_count_red = filtered_df.filter(filtered_df["Priority"] == 3).shape[0]
        problematic_count_red = format_number_european(problematic_count_red)

        problematic_count_orange = filtered_df.filter(filtered_df["Priority"] == 2).shape[0]
        problematic_count_orange = format_number_european(problematic_count_orange)

        # Using HTML to style text with color
        st.markdown(
            f"<div style='text-align:center;'> Heraf <span style='color:red; font-size:25px;'><b>{problematic_count_red}</b></span> sortlistede v√¶rdipapirer fra selskaber, "
            f"og <span style='color:#FE6E34; font-size:25px;'><b>{problematic_count_orange}</b></span> statsobligationer fra sortlistede lande.</div>",
            unsafe_allow_html=True,
        )

        problematic_count_yellow = filtered_df.filter(filtered_df["Priority"] == 1).shape[0]
        problematic_count_yellow = format_number_european(problematic_count_yellow)

        # Using HTML to style text with color
        st.markdown(" ")
        st.markdown(
            f"<div style='text-align:center;'> Derudover er der <span style='color:#FEB342; font-size:20px;'><b>{problematic_count_yellow}</b></span> potentielt problematiske v√¶rdipapirer. </div>",
            unsafe_allow_html=True,
        )

    # N√∏gletal
    with st.container(border=True):
        st.subheader("N√∏gletal")

        # Calculate the total number of investments
        antal_inv = format_number_european(len(filtered_df))

        st.write(f"**Antal investeringer:** {antal_inv}")

        # Calculate the total sum of 'Markedsv√¶rdi (DKK)' and display it in both DKK and millions
        total_markedsvaerdi = (
            filtered_df.select(pl.sum("Markedsv√¶rdi (DKK)")).to_pandas().iloc[0, 0]
        ).astype(int)

        markedsvaerdi_euro = format_number_european(total_markedsvaerdi)
        markedsvaerdi_euro_short = round_to_million_or_billion(total_markedsvaerdi, 1)
        st.write(f"**Total markedsv√¶rdi (DKK):** {markedsvaerdi_euro} {markedsvaerdi_euro_short}")

        # Filter for problematic investments and calculate the total sum of their 'Markedsv√¶rdi (DKK)'
        prob_df = filtered_df.filter(filtered_df["Priority"].is_in([2, 3]))
        prob_markedsvaerdi = (
            prob_df.select(pl.sum("Markedsv√¶rdi (DKK)")).to_pandas().iloc[0, 0]
        ).astype(int)

        prob_markedsvaerdi_euro = format_number_european(prob_markedsvaerdi)
        prob_markedsvaerdi_euro_short = round_to_million_or_billion(prob_markedsvaerdi, 1)
        st.write(
            f"**Markedsv√¶rdi af problematiske investeringer (DKK):** {prob_markedsvaerdi_euro} {prob_markedsvaerdi_euro_short}"
        )

with st.spinner("Henter data.."):
    if user_choice == "Hele landet" and selected_categories == [] and search_query == "":
        # Cache the data for "Hele landet"
        hele_landet_data = cache_data_for_hele_landet(filtered_df)
        display_dataframe(hele_landet_data)
    else:
        # No caching for other cases
        display_df = format_and_display_data(filtered_df)
        display_dataframe(display_df)


st.markdown(
    "\\* *Markedsv√¶rdien (DKK) er et √∏jebliksbillede. Tallene er oplyst af kommunerne og regionerne selv ud fra deres senest opgjorte opg√∏relser.*"
)

generate_organization_links(filtered_df, "Problematisk if√∏lge:")
st.markdown(
    '**Mere om v√¶rdipapirer udpeget af Gravercentret:** <a href="/Mulige_historier" target="_self">Mulige historier</a>',
    unsafe_allow_html=True,
)

filtered_df = filtered_df.to_pandas()
filtered_df.drop("Priority", axis=1, inplace=True)


with st.spinner("Klarg√∏r download til Excel.."):
    if user_choice == "Hele landet" and selected_categories == [] and search_query == "":
        # Cache and create the Excel file for "Hele landet"
        hele_landet_excel = cache_excel_for_hele_landet(filtered_df)

        # Create a download button for the Excel file
        st.download_button(
            label="Download til Excel",
            data=hele_landet_excel,
            file_name=f"Investeringer for {user_choice}{search_query}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )
    else:
        excel_data = to_excel_function(filtered_df)

        # Create a download button
        st.download_button(
            label="Download til Excel",
            data=excel_data,
            file_name=f"Investeringer for {user_choice}{search_query}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

with st.spinner("Henter AI-tekster.."):
    if user_choice not in [all_values, municipalities, regions, sams√∏, l√¶s√∏]:
        st.subheader(f"Eksklusions√•rsager for investeringer foretaget af {user_choice}: ")

        st.info(
            """Listen nedenfor er genereret med kunstig intelligens, og der tages derfor forbehold for fejl.
            Nedenst√•ende liste er muligvis ikke udt√∏mmende.""",
            icon="‚ÑπÔ∏è",
        )

        ai_text = get_ai_text(user_choice)

        st.markdown(ai_text)
